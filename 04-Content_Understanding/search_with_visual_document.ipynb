{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Visual Document Search with Azure Content Understanding\n",
        "\n",
        "Source: https://github.com/Azure-Samples/azure-ai-search-with-content-understanding-python\n",
        "\n",
        "(slightly modified for training purposes)\n",
        "\n",
        "## Objective\n",
        "This document illustrates an example workflow for how to leverage the Azure AI Content Understanding API to enhance the quality of document search.\n",
        "\n",
        "The sample will demonstrate the following steps:\n",
        "1. Extract the layout and content of a document using Azure AI Document Intelligence.\n",
        "2. For each figure in the document, extract its content with a custom analyzer using Azure AI Content Understanding, and insert it into the corresponding location in the document content.\n",
        "2. Chunk and embed the document content with LangChain and Azure OpenAI, and index them with Azure Search to generate an Azure Search index.\n",
        "3. Utilize an OpenAI chat model to search through content in the document with a natural language query.\n",
        "\n",
        "\n",
        "## Pre-requisites\n",
        "1. Follow the [README](README.md) to create the required resources for this sample.\n",
        "1. Install the required packages.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load environment variables"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from datetime import datetime # added for customizing AZURE_SEARCH_INDEX_NAME (if needed)\n",
        "\n",
        "load_dotenv(dotenv_path='../infra/credentials.env', override=True)\n",
        "\n",
        "# Load and validate Azure AI Services configs\n",
        "AZURE_AI_SERVICE_ENDPOINT = os.getenv(\"AZURE_AI_SERVICE_ENDPOINT\")\n",
        "AZURE_AI_SERVICE_API_VERSION = os.getenv(\"AZURE_AI_SERVICE_API_VERSION\") or \"2024-12-01-preview\"\n",
        "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_VERSION\") or \"2024-11-30\"\n",
        "\n",
        "# Load and validate Azure OpenAI configs\n",
        "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
        "AZURE_OPENAI_CHAT_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\") or \"2024-08-01-preview\"\n",
        "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"EMBEDDING_DEPLOYMENT_NAME\")\n",
        "AZURE_OPENAI_EMBEDDING_API_VERSION = os.getenv(\"AZURE_OPENAI_EMBEDDING_API_VERSION\") or \"2023-05-15\"\n",
        "\n",
        "# Load and validate Azure Search Services configs\n",
        "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
        "AZURE_SEARCH_KEY = os.getenv(\"AZURE_SEARCH_KEY\")\n",
        "AZURE_SEARCH_INDEX_NAME = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") or \"sample-index-visual-doc\""
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1744300548473
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current Azure AI Services endpoint: {AZURE_AI_SERVICE_ENDPOINT}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current Azure AI Services endpoint: https://ai-aifoundryupskillinghub687267079310.cognitiveservices.azure.com/\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1744299607504
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current Azure OpenAI endpoint: {AZURE_OPENAI_ENDPOINT}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current Azure OpenAI endpoint: https://ai-aifoundryupskillinghub687267079310.openai.azure.com/\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1744299610008
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current Azure AI Search endpoint: {AZURE_SEARCH_ENDPOINT}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current Azure AI Search endpoint: https://ai-search-abutneva687267079310.search.windows.net\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1744299612831
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File to analyze"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get the path to the file that will be analyzed\n",
        "# Sample report source: https://www.imf.org/en/Publications/CR/Issues/2024/07/18/United-States-2024-Article-IV-Consultation-Press-Release-Staff-Report-and-Statement-by-the-552100\n",
        "file = Path(\"assets/reports/sample_report_3pg.pdf\")"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1744299628021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "PosixPath('assets/reports/sample_report_3pg.pdf')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1744299629678
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create custom analyzer using chart and diagram understanding template"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import sys\n",
        "import uuid\n",
        "import pandas as pd # added for visualizing existing analyzers into a df\n",
        "import logging # added for visualizing response details from methods e.g. delete_analyzer()"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1744299633601
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# only if necessary, add the parent directory to the path to use shared modules\n",
        "# parent_dir = Path(Path.cwd()).parent\n",
        "# sys.path.append(str(parent_dir))\n",
        "\n",
        "# import the utility class AzureContentUnderstandingClient, which is a wrapper around the Azure Content Understanding REST API client\n",
        "from python.content_understanding_client import AzureContentUnderstandingClient"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1744299635742
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
        "credential = DefaultAzureCredential()\n",
        "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1744299640536
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#     credential = DefaultAzureCredential()\n",
        "#     # Test token acquisition\n",
        "#     token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "#     print(\"Successfully acquired token!\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Authentication failed: {str(e)}\")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create content understanding client"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "content_understanding_client = AzureContentUnderstandingClient(\n",
        "    endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
        "    api_version=AZURE_AI_SERVICE_API_VERSION,\n",
        "    # subscription_key= \"715b91dd-7c91-4bf2-8987-8640c7168071\",\n",
        "    token_provider=token_provider,\n",
        "    # x_ms_useragent=\"azure-ai-content-understanding-python/search_with_visusal_document\", # This header is used for sample usage telemetry, please comment out this line if you want to opt out.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1744299647380
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an analyzer"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get path to sample template\n",
        "ANALYZER_TEMPLATE_PATH = \"analyzer_templates/image_chart_diagram_understanding.json\""
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1744299658061
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create analyzer\n",
        "ANALYZER_ID = \"content-understanding-search-sample-\" + str(uuid.uuid4())\n",
        "print(f\"Creating analyzer with ID '{ANALYZER_ID}'...\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Creating analyzer with ID 'content-understanding-search-sample-b4d7ed6b-7958-4642-96cd-62d19be03db0'...\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1744299665019
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    response = content_understanding_client.begin_create_analyzer(ANALYZER_ID, analyzer_template_path=ANALYZER_TEMPLATE_PATH)\n",
        "    result = content_understanding_client.poll_result(response)\n",
        "    print(f'Analyzer {result[\"result\"][\"analyzerId\"]} created')\n",
        "    # print(json.dumps(result, indent=2))\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"Error in creating analyzer. Please double-check your analysis settings.\\nIf there is a conflict, you can delete the analyzer and then recreate it, or move to the next cell and use the existing analyzer.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Analyzer details for content-understanding-search-sample-b4d7ed6b-7958-4642-96cd-62d19be03db0:\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1744299670930
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the analyzer was created successfully\n",
        "result = content_understanding_client.get_analyzer_detail_by_id(ANALYZER_ID)\n",
        "print(json.dumps(result, indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"analyzerId\": \"content-understanding-search-sample-b4d7ed6b-7958-4642-96cd-62d19be03db0\",\n  \"description\": \"Extract detailed structured information from charts and diagrams.\",\n  \"createdAt\": \"2025-04-10T15:41:08Z\",\n  \"lastModifiedAt\": \"2025-04-10T15:41:08Z\",\n  \"config\": {\n    \"returnDetails\": false,\n    \"disableContentFiltering\": false\n  },\n  \"fieldSchema\": {\n    \"name\": \"ChartsAndDiagrams\",\n    \"fields\": {\n      \"Title\": {\n        \"type\": \"string\",\n        \"description\": \"Verbatim title of the chart.\"\n      },\n      \"ChartType\": {\n        \"type\": \"string\",\n        \"description\": \"The type of chart.\",\n        \"enum\": [\n          \"area\",\n          \"bar\",\n          \"box\",\n          \"bubble\",\n          \"candlestick\",\n          \"funnel\",\n          \"heatmap\",\n          \"histogram\",\n          \"line\",\n          \"pie\",\n          \"radar\",\n          \"rings\",\n          \"rose\",\n          \"treemap\"\n        ],\n        \"enumDescriptions\": {\n          \"histogram\": \"Continuous values on the x-axis, which distinguishes it from bar.\",\n          \"rose\": \"In contrast to pie charts, the sectors are of equal angles and differ in how far each sector extends from the center of the circle.\"\n        }\n      },\n      \"TopicKeywords\": {\n        \"type\": \"array\",\n        \"description\": \"Relevant topics associated with the chart, used for tagging.\",\n        \"items\": {\n          \"type\": \"string\",\n          \"examples\": [\n            \"Business and finance\",\n            \"Arts and culture\",\n            \"Education and academics\"\n          ]\n        }\n      },\n      \"DetailedDescription\": {\n        \"type\": \"string\",\n        \"description\": \"Detailed description of the chart or diagram, not leaving out any key information. Include numbers, trends, and other details.\"\n      },\n      \"Summary\": {\n        \"type\": \"string\",\n        \"description\": \"Detailed summary of the chart, including highlights and takeaways.\"\n      },\n      \"MarkdownDataTable\": {\n        \"type\": \"string\",\n        \"description\": \"Underlying data of the chart in tabular markdown format. Give markdown output with valid syntax and accurate numbers, and fill any uncertain values with empty cells. If not applicable, output an empty string.\"\n      },\n      \"AxisTitles\": {\n        \"type\": \"object\",\n        \"description\": \"Titles of the x and y axes.\",\n        \"properties\": {\n          \"xAxisTitle\": {\n            \"type\": \"string\"\n          },\n          \"yAxisTitle\": {\n            \"type\": \"string\"\n          }\n        }\n      },\n      \"FootnotesAndAnnotations\": {\n        \"type\": \"string\",\n        \"description\": \"All footnotes and textual annotations in the chart or diagram.\"\n      }\n    }\n  },\n  \"warnings\": [],\n  \"status\": \"ready\",\n  \"scenario\": \"image\"\n}\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1744299702602
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze document layout and compose with figure descriptions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions for document-figure composition"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install PyMuPDF\n",
        "\n",
        "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
        "from azure.ai.documentintelligence.models import AnalyzeResult\n",
        "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
        "import fitz\n",
        "from PIL import Image"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1744299711567
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define helper functions for document-figure composition\n",
        "def insert_figure_contents(md_content, figure_contents, span_offsets):\n",
        "    \"\"\"\n",
        "    Inserts the figure content for each of the provided figures in figure_contents\n",
        "    before the span offset of that figure in the given markdown content.\n",
        "\n",
        "    Args:\n",
        "    - md_content (str): The original markdown content.\n",
        "    - figure_contents (list[str]): The contents of each figure to insert.\n",
        "    - span_offsets (list[int]): The span offsets of each figure in order. These should be sorted and strictly increasing.\n",
        "\n",
        "    Returns:\n",
        "    - str: The modified markdown content with the the figure contents prepended to each figure's span.\n",
        "    \"\"\"\n",
        "    # NOTE: In this notebook, we only alter the Markdown content returned by the Document Intelligence API,\n",
        "    # and not the per-element spans in the API response. Thus, after figure content insertion, these per-element spans will be inaccurate.\n",
        "    # This may impact use cases like citation page number calculation.\n",
        "    # Additional code may be needed to correct the spans or otherwise infer the page numbers for each citation.\n",
        "    # The main purpose of the notebook is to show the feasibility of using Content Understanding with Azure Search for RAG chat applications.\n",
        "\n",
        "    # Validate span_offsets are sorted and strictly increasing\n",
        "    if span_offsets != sorted(span_offsets) or not all([o < span_offsets[i + 1] for i, o in enumerate(span_offsets) if i < len(span_offsets) - 1]):\n",
        "        raise ValueError(\"span_offsets should be sorted and strictly increasing.\")\n",
        "\n",
        "    # Split the content based on the provided spans\n",
        "    parts = []\n",
        "    preamble = None\n",
        "    for i, offset in enumerate(span_offsets):\n",
        "        if i == 0 and offset > 0:\n",
        "            preamble = md_content[0:offset]\n",
        "            parts.append(md_content[offset:span_offsets[i + 1]])\n",
        "        elif i == len(span_offsets) - 1:\n",
        "            parts.append(md_content[offset:])\n",
        "        else:\n",
        "            parts.append(md_content[offset:span_offsets[i + 1]])\n",
        "\n",
        "    # Join the parts back together with the figure content inserted\n",
        "    modified_content = \"\"\n",
        "    if preamble:\n",
        "        modified_content += preamble\n",
        "    for i, part in enumerate(parts):\n",
        "        modified_content += f\"<!-- FigureContent=\\\"{figure_contents[i]}\\\" -->\" + part\n",
        "\n",
        "    return modified_content\n",
        "\n",
        "def crop_image_from_pdf_page(pdf_path, page_number, bounding_box):\n",
        "    \"\"\"\n",
        "    Crops a region from a given page in a PDF and returns it as an image.\n",
        "\n",
        "    Args:    \n",
        "    - pdf_path (pathlib.Path): Path to the PDF file.\n",
        "    - page_number (int): The page number to crop from (0-indexed).\n",
        "    - bounding_box (tuple): A tuple of (x0, y0, x1, y1) coordinates for the bounding box.\n",
        "    \n",
        "    Returns:\n",
        "    - PIL.Image: A PIL Image of the cropped area.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    page = doc.load_page(page_number)\n",
        "    \n",
        "    # Cropping the page. The rect requires the coordinates in the format (x0, y0, x1, y1).\n",
        "    bbx = [x * 72 for x in bounding_box]\n",
        "    rect = fitz.Rect(bbx)\n",
        "    pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72), clip=rect)\n",
        "    \n",
        "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "    \n",
        "    doc.close()\n",
        "\n",
        "    return img\n",
        "\n",
        "def format_content_understanding_result(content_understanding_result):\n",
        "    \"\"\"\n",
        "    Formats the JSON output of the Content Understanding result as Markdown for downstream usage in text.\n",
        "    \n",
        "    Args:\n",
        "    - content_understanding_result (dict): A dictionary containing the output from Content Understanding.\n",
        "\n",
        "    Returns:\n",
        "    - str: A Markdown string of the result content.\n",
        "    \"\"\"\n",
        "    def _format_result(key, result):\n",
        "        result_type = result[\"type\"]\n",
        "        if result_type in [\"string\", \"integer\", \"number\", \"boolean\"]:\n",
        "            return f\"**{key}**: \" + str(result[f'value{result_type.capitalize()}']) + \"\\n\"\n",
        "        elif result_type == \"array\":\n",
        "            return f\"**{key}**: \" + ', '.join([str(result[\"valueArray\"][i][f\"value{r['type'].capitalize()}\"]) for i, r in enumerate(result[\"valueArray\"])]) + \"\\n\"\n",
        "        elif result_type == \"object\":\n",
        "            return f\"**{key}**\\n\" + ''.join([_format_result(f\"{key}.{k}\", result[\"valueObject\"][k]) for k in result[\"valueObject\"]])\n",
        "\n",
        "    fields = content_understanding_result['result']['contents'][0]['fields']\n",
        "    markdown_result = \"\"\n",
        "    for field in fields:\n",
        "        markdown_result += _format_result(field, fields[field])\n",
        "\n",
        "    return markdown_result"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1744299713529
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract figures and run content understanding"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import json\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1744299716452
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "PosixPath('assets/reports/sample_report_3pg.pdf')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1744299717467
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# observed computation time: ~1 minute for 3 pages\n",
        "# the output is cached in a file called 'sample_report.cache'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Content Understanding on each figure, format figure contents, and insert figure contents into corresponding document locations\n",
        "with open(file, 'rb') as f:\n",
        "    pdf_bytes = f.read()\n",
        "\n",
        "    document_intelligence_client = DocumentIntelligenceClient(\n",
        "        endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
        "        api_version=AZURE_DOCUMENT_INTELLIGENCE_API_VERSION,\n",
        "        credential=credential,\n",
        "        output=str('figures')\n",
        "    )\n",
        "\n",
        "    poller = document_intelligence_client.begin_analyze_document(\n",
        "        \"prebuilt-layout\",\n",
        "        AnalyzeDocumentRequest(bytes_source=pdf_bytes),\n",
        "        output=[str('figures')],\n",
        "        features=['ocrHighResolution'],\n",
        "        output_content_format=\"markdown\"\n",
        "    )\n",
        "\n",
        "    result: AnalyzeResult = poller.result()\n",
        "    \n",
        "    md_content = result.content\n",
        "\n",
        "    figure_contents = []\n",
        "    if result.figures:\n",
        "        print(\"Extracting figure contents with Content Understanding.\")\n",
        "        for figure_idx, figure in enumerate(result.figures):\n",
        "            for region in figure.bounding_regions:\n",
        "                    # Uncomment the below to print out the bounding regions of each figure\n",
        "                    # print(f\"Figure {figure_idx + 1} body bounding regions: {region}\")\n",
        "                    # To learn more about bounding regions, see https://aka.ms/bounding-region\n",
        "                    bounding_box = (\n",
        "                            region.polygon[0],  # x0 (left)\n",
        "                            region.polygon[1],  # y0 (top\n",
        "                            region.polygon[4],  # x1 (right)\n",
        "                            region.polygon[5]   # y1 (bottom)\n",
        "                        )\n",
        "            page_number = figure.bounding_regions[0]['pageNumber']\n",
        "            cropped_img = crop_image_from_pdf_page(file, page_number - 1, bounding_box)\n",
        "\n",
        "            os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "            figure_filename = f\"figure_{figure_idx + 1}.png\"\n",
        "            # Full path for the file\n",
        "            figure_filepath = os.path.join(\"figures\", figure_filename)\n",
        "\n",
        "            # Save the figure\n",
        "            cropped_img.save(figure_filepath)\n",
        "            bytes_io = io.BytesIO()\n",
        "            cropped_img.save(bytes_io, format='PNG')\n",
        "            cropped_img = bytes_io.getvalue()\n",
        "\n",
        "            # Collect formatted content from the figure\n",
        "            content_understanding_response = content_understanding_client.begin_analyze(ANALYZER_ID, figure_filepath)\n",
        "            content_understanding_result = content_understanding_client.poll_result(content_understanding_response, timeout_seconds=1000)\n",
        "            figure_content = format_content_understanding_result(content_understanding_result)\n",
        "            figure_contents.append(figure_content)\n",
        "            print(f\"Figure {figure_idx + 1} contents:\\n{figure_content}\")\n",
        "\n",
        "        # Insert figure content into corresponding location in document\n",
        "        md_content = insert_figure_contents(md_content, figure_contents, [f.spans[0][\"offset\"] for f in result.figures])\n",
        "    \n",
        "    # Save results as a JSON file to cache the result for downstream use\n",
        "    result.content = md_content\n",
        "    output = {}\n",
        "    output['analyzeResult'] = result.as_dict()\n",
        "    output = json.dumps(output)\n",
        "    with open('sample_report.cache', 'w') as f:\n",
        "        f.write(output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Extracting figure contents with Content Understanding.\nFigure 1 contents:\n**Title**: 2023 Real GDP\n**ChartType**: bar\n**TopicKeywords**: Business and finance, Economics\n**DetailedDescription**: The bar chart titled '2023 Real GDP' shows the percent deviation from the pre-crisis trend for various regions and countries. The United States is the only region with a positive deviation, slightly above 0.5%. Japan, Canada, and the Euro Area have negative deviations, all around -1.0%. The United Kingdom has the largest negative deviation, close to -4.0%. The G-20 Emerging Markets (EMs) also show a significant negative deviation, slightly above -3.0%.\n**Summary**: The chart illustrates the 2023 Real GDP percent deviation from the pre-crisis trend for several regions. The US shows a positive deviation, while Japan, Canada, Euro Area, UK, and G-20 EMs show negative deviations, with the UK having the largest negative deviation.\n**MarkdownDataTable**: | Region     | Percent Deviation |\n|------------|------------------|\n| US         | 0.5              |\n| Japan      | -1.0             |\n| Canada     | -1.0             |\n| Euro Area  | -1.0             |\n| UK         | -4.0             |\n| G-20 EMs   | -3.0             |\n**AxisTitles**\n**AxisTitles.xAxisTitle**: \n**AxisTitles.yAxisTitle**: Percent Deviation\n**FootnotesAndAnnotations**: (percent deviation from pre-crisis trend)\n\nFigure 2 contents:\n**Title**: Federal Government Spending\n**ChartType**: bar\n**TopicKeywords**: Business and finance, Economics, Government\n**DetailedDescription**: The chart displays federal government spending as a percentage of GDP, relative to the 2019 level, from 2020 to 2023. The spending is categorized into four groups: Individuals, Businesses, SLGs (State and Local Governments), and Others. In 2020, the total spending was approximately 9% of GDP, with Individuals accounting for the largest share, followed by Others, Businesses, and SLGs. In 2021, the spending decreased to around 5% of GDP, with Individuals still being the largest category, but with reduced contributions from Others and Businesses. By 2022, the spending further decreased to about 1% of GDP, with Individuals and Others contributing equally. In 2023, the spending slightly increased to about 2% of GDP, with Individuals again being the largest category, followed by Others, Businesses, and SLGs.\n**Summary**: The chart illustrates the trend of federal government spending from 2020 to 2023, showing a significant decrease from 9% of GDP in 2020 to about 2% in 2023. The spending is broken down into categories, with Individuals consistently being the largest contributor throughout the years.\n**MarkdownDataTable**: | Year | Individuals | Businesses | SLGs | Others |\n|------|-------------|------------|------|--------|\n| 2020 | 6           | 1          | 0.5  | 1.5    |\n| 2021 | 3.5         | 0.5        | 0.5  | 0.5    |\n| 2022 | 0.5         | 0.2        | 0.1  | 0.2    |\n| 2023 | 1           | 0.3        | 0.2  | 0.5    |\n**AxisTitles**\n**AxisTitles.xAxisTitle**: Year\n**AxisTitles.yAxisTitle**: Percent of GDP\n**FootnotesAndAnnotations**: Source: U.S. Department of Treasury; Small Business Administration; Congressional Research Services; Office of Management and Budget; IMF staff calculation.\nNote: 'Federal spending is measured as the increase relative to the 2019 level; Others included defense spending, capital investment, interest spending, and other items not directly attributable to firms, households, or subnational governments.\n\nFigure 3 contents:\n**Title**: General Government Structural Primary Balance\n**ChartType**: bar\n**TopicKeywords**: Business and finance, Economics, Fiscal policy, Government\n**DetailedDescription**: The chart compares the general government structural primary balance for the US and the Euro Area in two different periods: pre-pandemic (2019) and during the fiscal impulse period. The structural primary balance is a measure of the government's fiscal position, excluding interest payments on debt. In 2019, the US had a structural primary balance of approximately -3, while the Euro Area had a slightly better balance, close to -2. During the fiscal impulse period, both regions experienced significant increases in cumulative deficits. The US's deficit increased to around -8, while the Euro Area's deficit increased even more dramatically to about -12.\n**Summary**: The chart illustrates the change in general government structural primary balance from 2019 to the fiscal impulse period for the US and Euro Area. Both regions saw increased deficits, with the Euro Area experiencing a larger fiscal impulse.\n**MarkdownDataTable**: | Region     | Period          | Structural Primary Balance |\n|------------|-----------------|----------------------------|\n| US         | Pre-pandemic    | -3                         |\n| Euro Area  | Pre-pandemic    | -2                         |\n| US         | Fiscal impulse  | -8                         |\n| Euro Area  | Fiscal impulse  | -12                        |\n**AxisTitles**\n**AxisTitles.xAxisTitle**: Period\n**AxisTitles.yAxisTitle**: General Government Structural Primary Balance\n**FootnotesAndAnnotations**: \n\nFigure 4 contents:\n**Title**: Asset Price Indices (Dec 2019 = 100)\n**ChartType**: line\n**TopicKeywords**: Business and finance, Economics, Real estate, Stock market\n**DetailedDescription**: The chart displays two asset price indices from December 2019 to September 2023, with December 2019 set as the base value of 100. The Case-Shiller House Price Index is represented by a blue line, while the S&P 500 Index is shown in orange. The Case-Shiller House Price Index shows a steady increase over the period, starting at 100 in December 2019 and reaching approximately 150 by September 2023. The S&P 500 Index exhibits more volatility, initially dropping below 100 in early 2020, then rising sharply to peak around 160 in late 2021, followed by fluctuations and ending at approximately 160 in September 2023.\n**Summary**: The Case-Shiller House Price Index has shown a consistent upward trend from December 2019 to September 2023, indicating a steady increase in house prices. In contrast, the S&P 500 Index has experienced significant volatility, with a sharp rise and subsequent fluctuations, ultimately reaching a similar level to the Case-Shiller Index by September 2023.\n**MarkdownDataTable**: | Date     | Case-Shiller House Price Index | S&P 500 Index |\n|----------|-------------------------------|---------------|\n| Dec-2019 | 100                           | 100           |\n| Sep-2020 | 110                           | 120           |\n| Jun-2021 | 130                           | 150           |\n| Mar-2022 | 140                           | 160           |\n| Dec-2022 | 145                           | 150           |\n| Sep-2023 | 150                           | 160           |\n**AxisTitles**\n**AxisTitles.xAxisTitle**: \n**AxisTitles.yAxisTitle**: Index Value\n**FootnotesAndAnnotations**: Source: S&P Dow Jones Indices LLC; Haver.\n\nFigure 5 contents:\n**Title**: (US$ trillions, constant 2019 prices)\n**ChartType**: bar\n**TopicKeywords**: Business and finance, Economics, Income distribution\n**DetailedDescription**: The bar chart displays the distribution of income across different segments of the population, divided into quintiles, for the years 2009, 2019, and 2023. The income is measured in US$ trillions, adjusted to constant 2019 prices. The segments are Bottom 20%, 21-40%, 41-60%, 61-80%, and Top 20% (RHS). The Top 20% segment is shown on a secondary axis (RHS) with a different scale. In 2009, the Bottom 20% had the lowest income, while the Top 20% had the highest. Over the years, income has increased across all segments, with the Top 20% showing the most significant growth. By 2023, the Top 20% segment reached nearly 90 trillion, while the Bottom 20% remained below 2 trillion.\n**Summary**: The chart illustrates the growth in income across different population segments from 2009 to 2023, with the Top 20% showing the most substantial increase. The income is measured in constant 2019 US$ trillions, highlighting economic disparities.\n**MarkdownDataTable**: | Segment   | 2009 | 2019 | 2023 |\n|-----------|------|------|------|\n| Bottom 20%| 1    | 2    | 2    |\n| 21-40%    | 2    | 3    | 3    |\n| 41-60%    | 3    | 4    | 5    |\n| 61-80%    | 5    | 7    | 8    |\n| Top 20%   | 60   | 80   | 90   |\n**AxisTitles**\n**AxisTitles.xAxisTitle**: \n**AxisTitles.yAxisTitle**: US$ trillions\n**FootnotesAndAnnotations**: Source: Federal Reserve; Bureau of Economic Analysis\n\nFigure 6 contents:\n**Title**: \n**ChartType**: line\n**TopicKeywords**: Business and finance, Economics\n**DetailedDescription**: The line chart shows a trend over time from 2018 Q1 to 2024 Q1. The values start at approximately 2.5 in 2018 Q1, showing a slight increase and fluctuation until 2020 Q1. From 2020 Q1, there is a sharp decline reaching a low point of approximately 1.5 in 2021 Q1. After this point, the values begin to rise steadily, surpassing the initial value by 2023 Q3 and continuing to increase sharply, reaching a peak of 3 by 2024 Q1.\n**Summary**: The chart illustrates a significant dip in values around 2020 Q1 to 2021 Q1, followed by a strong recovery and growth, reaching a peak by 2024 Q1. This trend may indicate economic recovery or growth after a downturn.\n**MarkdownDataTable**: | Quarter | Value |\n|---------|-------|\n| 2018Q1  | 2.5   |\n| 2018Q4  | 2.6   |\n| 2019Q3  | 2.7   |\n| 2020Q2  | 2.4   |\n| 2021Q1  | 1.5   |\n| 2021Q4  | 2.0   |\n| 2022Q3  | 2.5   |\n| 2023Q2  | 2.8   |\n| 2024Q1  | 3.0   |\n**AxisTitles**\n**AxisTitles.xAxisTitle**: Quarter\n**AxisTitles.yAxisTitle**: Value\n**FootnotesAndAnnotations**: Source: Federal Reserve.\n\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1744299821697
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment the first line below to load in a previously cached result.\n",
        "# output = open(\"sample_report.cache\").read()\n",
        "document_content = json.loads(output)\n",
        "document_content = document_content['analyzeResult']['content']"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1744299828441
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(document_content)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "str"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1744299830725
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nicely print document content\n",
        "# print(document_content)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enhanced RAG"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple (and not exhaustive) starting point. Feel free to give your own chunking strategies a try!\n",
        "\n",
        "...and replace langchain with Azure AI Foundry SDK! ðŸ˜Š\n",
        "\n",
        "In the following example:\n",
        "- we use semantic chunking to chunk the output from document intelligence (enriched with content understading on charts)\n",
        "- we use an embedding model to embed the chunks and store them in Azure AI Search for retrieval\n",
        "- we retrieve the most relevant chunks based on a sample query (e.g. \"Which is the country with the lowest GDP in 2023?\")\n",
        "- we inject the question and the retrieved content in the LLM prompt to give the LLM a context\n",
        "- we inspect the LLM response"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chunk text by splitting with Markdown header splitting and recursive character splitting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Configure langchain text splitting settings\n",
        "EMBEDDING_CHUNK_SIZE = 512\n",
        "EMBEDDING_CHUNK_OVERLAP = 20\n",
        "headers_to_split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "    (\"###\", \"Header 3\")\n",
        "]\n",
        "\n",
        "# First split text using Markdown headers\n",
        "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
        "chunks = text_splitter.split_text(document_content)\n",
        "\n",
        "# Then further split the text using recursive character text splitting\n",
        "char_text_splitter = RecursiveCharacterTextSplitter(separators=[\"<!--\", \"\\n\\n\", \"#\"], chunk_size=EMBEDDING_CHUNK_SIZE, chunk_overlap=EMBEDDING_CHUNK_OVERLAP, is_separator_regex=True)\n",
        "chunks = char_text_splitter.split_documents(chunks)\n",
        "\n",
        "print(\"Number of chunks: \" + str(len(chunks)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of chunks: 19\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1744299835602
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate embeddings and populate the Azure AI Search index"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain.vectorstores.azuresearch import AzureSearch"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1744299839676
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Embedding model: {AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME}\")\n",
        "print(f\"Embedding API version: {AZURE_OPENAI_EMBEDDING_API_VERSION}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Embedding model: text-embedding-ada-002\nEmbedding API version: 2023-05-15\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1744299842452
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aoai_embeddings = AzureOpenAIEmbeddings(model=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
        "                                        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "                                        azure_ad_token_provider=token_provider,\n",
        "                                        api_version=AZURE_OPENAI_EMBEDDING_API_VERSION)"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1744299848565
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(aoai_embeddings)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "langchain_openai.embeddings.azure.AzureOpenAIEmbeddings"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1744299851478
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure AI Search resource\n",
        "print(f\"Search endpoint: {AZURE_SEARCH_ENDPOINT}\")\n",
        "\n",
        "# Azure AI Search index name\n",
        "AZURE_SEARCH_INDEX_NAME = f\"{AZURE_SEARCH_INDEX_NAME}-{datetime.now().strftime('%Y-%m-%d')}\"\n",
        "print(f\"Saving on index: {AZURE_SEARCH_INDEX_NAME}\") #-{datetime.now().strftime('%Y-%m-%d')}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Search endpoint: https://ai-search-abutneva687267079310.search.windows.net\nSaving on index: my-index-2025-04-10\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1744300570790
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT:\n",
        "# 1) grant user roles Search Index Data Contributor + Search Service Contributor for the Azure AI Search resource\n",
        "# 2) Settings --> Keys --> API Access Control --> select Role-based access control\n",
        "vector_store = AzureSearch(\n",
        "    azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
        "    azure_search_key=AZURE_SEARCH_KEY,\n",
        "    index_name= AZURE_SEARCH_INDEX_NAME, #f\"{AZURE_SEARCH_INDEX_NAME}-{datetime.now().strftime('%Y-%m-%d')}\",  #\"my-first-index\",\n",
        "    embedding_function=aoai_embeddings.embed_query,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1744300573490
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a one-time operation to add the documents to the vector store. Comment out this line if you are re-running this cell with the same index.\n",
        "vector_store.add_documents(documents=chunks)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "['Mzg2ZjYyYzctMzQ0MC00OWQ4LWJhYWEtYmRhYTE0MmRhNWNj',\n 'MGQ1OTU0OWEtMzlmNy00NDZkLTkwZmYtNDJiZDIxZDRkOTdi',\n 'YTViZGE5MzYtOGY1Yi00MTZjLWE1YTctZjJhMTBjYWE5MGMz',\n 'NGIwOGE4MWItNTVjNS00MzQxLWE1ZTItNDg1MzE1YTkwODI4',\n 'MTJhMGE2NTctZjMwZC00Zjc4LWJjNjUtZGMzZjFmYTQ2ZTY1',\n 'MmViYzk1ZjgtNTFhOS00MzY3LWIyODctODVhNGY3ZmE1MjU2',\n 'M2MxZjJhN2UtMzhjYS00MDcxLTk1OGQtYTEwMGQ5OWUzY2Nl',\n 'YmRjNDUwMDQtYmU4Ny00NzIxLWIyYjMtZDEwOGNiZmU3Y2Y2',\n 'MWQzZmY3Y2QtMTg2Ny00OGM2LThkMGYtOGYwNzNjMDE5Zjdk',\n 'ZmJmYjY0Y2QtYTQ1YS00MmEzLTk1NjgtZDIwZWFmYTdkMzBl',\n 'ZDc3NzE5NmMtYmM1MC00MzQ2LTk3NDMtZGQ4ZGNiNTEzOTBk',\n 'N2ZjZDJlNjYtZGYzYS00OGE3LWEwZTItYmM5NGEwN2I0YTkx',\n 'MmIwNDY3NzYtM2U2MS00ZmRhLThmNTAtNGM0YWI2OTJmYWFm',\n 'Nzg4ZDFhNzAtOWE2YS00ZTA4LWFiODctOTM1MjU4MjJhN2Jj',\n 'MTRhYTE4YWQtOGVkMS00MTgxLWIxODEtZGJjODAzMzllMjdi',\n 'NDZiNThlYjMtZDUxMy00NWRhLTg0MTktOWI4ZWVmNzQ3ZjA1',\n 'NWM5ODFiNjgtOTczOC00MWJhLWI2ZWUtNWU4N2JmNGQzOTYw',\n 'ZmVjOTc1Y2ItNGM4OC00MDVhLTk3M2EtNWM3YzQ4M2EwZDM3',\n 'OTM0MjZhYmMtZGE2MC00ZWI4LWI0ZWMtOTJhNDJkMjMyODE4']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1744300576836
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query vector index to retrieve relevant documents"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the retriever that will be used to query the index for similar documents\n",
        "retriever = vector_store.as_retriever(search_type=\"similarity\")"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1744300624591
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve relevant documents\n",
        "# query = \"What was the crude oil production in 2019?\"\n",
        "query = \"What was the country with the lowest real GDP in 2023?\"\n",
        "retrieved_docs = retriever.invoke(query)"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1744300627410
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print retrieved documents\n",
        "for doc in retrieved_docs:\n",
        "    print(\"Document id:\", doc.metadata['id'])\n",
        "    print(\"Content:\", doc.page_content)\n",
        "    print(\"=\" * 50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Document id: YTViZGE5MzYtOGY1Yi00MTZjLWE1YTctZjJhMTBjYWE5MGMz\nContent: <!-- FigureContent=\"**Title**: 2023 Real GDP\n**ChartType**: bar\n**TopicKeywords**: Business and finance, Economics\n**DetailedDescription**: The bar chart titled '2023 Real GDP' shows the percent deviation from the pre-crisis trend for various regions and countries. The United States is the only region with a positive deviation, slightly above 0.5%. Japan, Canada, and the Euro Area have negative deviations, all around -1.0%. The United Kingdom has the largest negative deviation, close to -4.0%. The G-20 Emerging Markets (EMs) also show a significant negative deviation, slightly above -3.0%.\n**Summary**: The chart illustrates the 2023 Real GDP percent deviation from the pre-crisis trend for several regions. The US shows a positive deviation, while Japan, Canada, Euro Area, UK, and G-20 EMs show negative deviations, with the UK having the largest negative deviation.\n**MarkdownDataTable**: | Region     | Percent Deviation |\n|------------|------------------|\n| US         | 0.5              |\n| Japan      | -1.0             |\n| Canada     | -1.0             |\n| Euro Area  | -1.0             |\n| UK         | -4.0             |\n| G-20 EMs   | -3.0             |\n**AxisTitles**\n**AxisTitles.xAxisTitle**:\n**AxisTitles.yAxisTitle**: Percent Deviation\n**FootnotesAndAnnotations**: (percent deviation from pre-crisis trend)\n\" --><figure>  \nG-20 EMs  \n</figure>  \nSources: IMF World Economic Outlook.\nNote: Bars show the difference in real output in 2023 and anticipated output for the same\nperiod prior to the crisis (January 2020 WEO).\n==================================================\nDocument id: MGQ1OTU0OWEtMzlmNy00NDZkLTkwZmYtNDJiZDIxZDRkOTdi\nContent: # A RESILIENT ECONOMY  \n1\\. The U.S. economy has turned in a remarkable performance over the past few years.  \nRather than facing lasting negative hysteresis effects from the pandemic, the U.S. is the only G20\neconomy that is now operating above the levels of output and employment expected prior to the\npandemic. Q4/Q4 growth in 2023 (at 3.1 percent)\nwas almost three times that expected at the time\n2023 Real GDP\n(percent deviation from pre-crisis trend)\nof the last Article IV and core PCE inflation was\n1.0\nalmost 1 percentage point lower. The rebound has\nbeen characterized by important gains on both the\n-0.5\ndemand and supply side which has allowed\n-2.0\ninflation to head back to the FOMC's medium-term\n-3.5\ntarget without a major dislocation in the real\neconomy. The strength of the U.S. economy and\n-5.0\nthe relatively quick disinflation have had large,\nUS\nJapan\nCanada\nEuro Area\nUK\npositive spillovers to the world economy.  \n\n==================================================\nDocument id: MTRhYTE4YWQtOGVkMS00MTgxLWIxODEtZGJjODAzMzllMjdi\nContent: <!-- PageHeader=\"UNITED STATES\" -->  \n4\\.\nThis strength in aggregate consumption, however, masks an upswing in poverty and\nrising signs of economic distress among low-income households. During the recovery from the\npandemic, labor shortages lifted real wages at the bottom of the income distribution and led to a\ncompression of wage inequality.2 Despite these gains, poverty increased by 4.6 percentage points in\n2022 and the child poverty rate more than doubled.3 This rise in poverty can be directly attributed to\nthe expiration of pandemic-era assistance, particularly changes that had been made to the Child Tax\nCredit and the Earned Income Tax Credit (EITC).\nDeliquency Rate on Credit Card Loans - All Commercial Banks\n(percent, seasonally Adjusted)\nThe increased pressure on lower income\nhouseholds is becoming more visible in an\n3\nupswing in delinquencies on revolving credit.\nFurthermore, worsening housing affordability has\n2.5\naggravated access to shelter, particularly for the\nyoung and lower income households. This is\n2\nevident in the number of people experiencing\nhomelessness, which has risen to the highest level\nsince data began to be compiled in 2007.4\n1.5\n2018Q1 2018Q4 2019Q3 2020Q2 2021Q1 2021Q4 2022Q3 2023Q2 2024Q1  \n\n==================================================\nDocument id: MTJhMGE2NTctZjMwZC00Zjc4LWJjNjUtZGMzZjFmYTQ2ZTY1\nContent: # A. What Has Underpinned the Post-Pandemic Strength in Demand?  \n2\\. The unprecedented increase in the fiscal deficit during the depths of the pandemic\nprovided significant fuel to demand. The cumulative increase in federal spending in 2020-21 was\naround 19 percent of GDP. While somewhat smaller than that of the Euro Area, the extraordinary\nbreadth of this (relatively untargeted) fiscal support is providing a material boost to aggregate\ndemand in 2023-24 through multiple channels:  \nÂ· Federal transfers to households (through stimulus checks, food assistance, child and earned\nincome tax credits, and unemployment insurance), combined with foregone consumption and\ndebt rescheduling (e.g., of mortgages and student loans), added an estimated 10 percent of\nGDP to household savings by end-2021. These resources were then subsequently available to\nsupport consumption even as real disposable income fell (due to the post-pandemic burst of\ninflation).  \nÂ· Large transfers to state and local governments prevented a drawdown of rainy-day funds in the\npandemic, providing subnational governments with sizable buffers which, in turn, allowed them\nto maintain their spending above pre-pandemic levels.  \nÂ· Around 31/2 percent of GDP in federal loans provided through the Payroll Protection Program\nwere subsequently forgiven, bolstering corporate balance sheets. Other targeted pandemic\nmeasures (e.g., for airlines) also supported the corporate sector.  \n\n==================================================\n"
        }
      ],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1744300632065
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate answer to query"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define system prompt template for chat model\n",
        "prompt = \"\"\"\n",
        "You are an expert in document analysis. You are proficient in reading and analyzing technical reports. You are good at numerical reasoning and have a good understanding of financial concepts. You are given a question which you need to answer based on the references provided. To answer this question, you may first read the question carefully to know what information is required or helpful to answer the question. Then, you may read the references to find the relevant information.\n",
        "\n",
        "If you find enough information to answer the question, you can first write down your thinking process and then provide a concise answer at the end.\n",
        "If you find that there is not enough information to answer the question, you can state that there is insufficient information.\n",
        "If you are not able or sure how to answer the question, say that you are not able to answer the question.\n",
        "Do not provide any information that is not present in the references.\n",
        "References are in markdown format, you may follow the markdown syntax to better understand the references.\n",
        "\n",
        "---\n",
        "References:\n",
        "{context}\n",
        "---\n",
        "\n",
        "Now, here is the question:\n",
        "---\n",
        "Question:\n",
        "{question}\n",
        "---\n",
        "Thinking Process::: \n",
        "Answer::: \n",
        "\"\"\"\n",
        "\n",
        "# Helper function to generate the formatted context from each retrieved document\n",
        "def generate_context(chunks):\n",
        "    context = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        s = (f'Source {i} Metadata: {chunk.metadata}\\n'\n",
        "                f'Source {i} Content: {chunk.page_content}')\n",
        "        context.append(s)\n",
        "    context = '\\n---\\n'.join(context)\n",
        "    return context\n",
        "\n",
        "# Remove redundant chunks\n",
        "appeared = set()\n",
        "unique_chunks = []\n",
        "for chunk in retrieved_docs:\n",
        "    chunk_id = chunk.metadata['id']\n",
        "    if chunk_id not in appeared:\n",
        "        appeared.add(chunk_id)\n",
        "        unique_chunks.append(chunk)\n",
        "context = generate_context(unique_chunks)\n",
        "\n",
        "# Format the prompt with the provided query and formatted context\n",
        "# The context is given by the retrieved documents\n",
        "prompt = prompt.format(question=query,\n",
        "                       context=context)"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1744300642496
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nYou are an expert in document analysis. You are proficient in reading and analyzing technical reports. You are good at numerical reasoning and have a good understanding of financial concepts. You are given a question which you need to answer based on the references provided. To answer this question, you may first read the question carefully to know what information is required or helpful to answer the question. Then, you may read the references to find the relevant information.\n\nIf you find enough information to answer the question, you can first write down your thinking process and then provide a concise answer at the end.\nIf you find that there is not enough information to answer the question, you can state that there is insufficient information.\nIf you are not able or sure how to answer the question, say that you are not able to answer the question.\nDo not provide any information that is not present in the references.\nReferences are in markdown format, you may follow the markdown syntax to better understand the references.\n\n---\nReferences:\nSource 0 Metadata: {'id': 'YTViZGE5MzYtOGY1Yi00MTZjLWE1YTctZjJhMTBjYWE5MGMz', 'Header 1': 'A RESILIENT ECONOMY'}\nSource 0 Content: <!-- FigureContent=\"**Title**: 2023 Real GDP\n**ChartType**: bar\n**TopicKeywords**: Business and finance, Economics\n**DetailedDescription**: The bar chart titled '2023 Real GDP' shows the percent deviation from the pre-crisis trend for various regions and countries. The United States is the only region with a positive deviation, slightly above 0.5%. Japan, Canada, and the Euro Area have negative deviations, all around -1.0%. The United Kingdom has the largest negative deviation, close to -4.0%. The G-20 Emerging Markets (EMs) also show a significant negative deviation, slightly above -3.0%.\n**Summary**: The chart illustrates the 2023 Real GDP percent deviation from the pre-crisis trend for several regions. The US shows a positive deviation, while Japan, Canada, Euro Area, UK, and G-20 EMs show negative deviations, with the UK having the largest negative deviation.\n**MarkdownDataTable**: | Region     | Percent Deviation |\n|------------|------------------|\n| US         | 0.5              |\n| Japan      | -1.0             |\n| Canada     | -1.0             |\n| Euro Area  | -1.0             |\n| UK         | -4.0             |\n| G-20 EMs   | -3.0             |\n**AxisTitles**\n**AxisTitles.xAxisTitle**:\n**AxisTitles.yAxisTitle**: Percent Deviation\n**FootnotesAndAnnotations**: (percent deviation from pre-crisis trend)\n\" --><figure>  \nG-20 EMs  \n</figure>  \nSources: IMF World Economic Outlook.\nNote: Bars show the difference in real output in 2023 and anticipated output for the same\nperiod prior to the crisis (January 2020 WEO).\n---\nSource 1 Metadata: {'id': 'MGQ1OTU0OWEtMzlmNy00NDZkLTkwZmYtNDJiZDIxZDRkOTdi', 'Header 1': 'A RESILIENT ECONOMY'}\nSource 1 Content: # A RESILIENT ECONOMY  \n1\\. The U.S. economy has turned in a remarkable performance over the past few years.  \nRather than facing lasting negative hysteresis effects from the pandemic, the U.S. is the only G20\neconomy that is now operating above the levels of output and employment expected prior to the\npandemic. Q4/Q4 growth in 2023 (at 3.1 percent)\nwas almost three times that expected at the time\n2023 Real GDP\n(percent deviation from pre-crisis trend)\nof the last Article IV and core PCE inflation was\n1.0\nalmost 1 percentage point lower. The rebound has\nbeen characterized by important gains on both the\n-0.5\ndemand and supply side which has allowed\n-2.0\ninflation to head back to the FOMC's medium-term\n-3.5\ntarget without a major dislocation in the real\neconomy. The strength of the U.S. economy and\n-5.0\nthe relatively quick disinflation have had large,\nUS\nJapan\nCanada\nEuro Area\nUK\npositive spillovers to the world economy.  \n\n---\nSource 2 Metadata: {'id': 'MTRhYTE4YWQtOGVkMS00MTgxLWIxODEtZGJjODAzMzllMjdi', 'Header 1': 'UNITED STATES', 'Header 2': '3. Rising household wealth has been a key determinant in supporting consumer demand'}\nSource 2 Content: <!-- PageHeader=\"UNITED STATES\" -->  \n4\\.\nThis strength in aggregate consumption, however, masks an upswing in poverty and\nrising signs of economic distress among low-income households. During the recovery from the\npandemic, labor shortages lifted real wages at the bottom of the income distribution and led to a\ncompression of wage inequality.2 Despite these gains, poverty increased by 4.6 percentage points in\n2022 and the child poverty rate more than doubled.3 This rise in poverty can be directly attributed to\nthe expiration of pandemic-era assistance, particularly changes that had been made to the Child Tax\nCredit and the Earned Income Tax Credit (EITC).\nDeliquency Rate on Credit Card Loans - All Commercial Banks\n(percent, seasonally Adjusted)\nThe increased pressure on lower income\nhouseholds is becoming more visible in an\n3\nupswing in delinquencies on revolving credit.\nFurthermore, worsening housing affordability has\n2.5\naggravated access to shelter, particularly for the\nyoung and lower income households. This is\n2\nevident in the number of people experiencing\nhomelessness, which has risen to the highest level\nsince data began to be compiled in 2007.4\n1.5\n2018Q1 2018Q4 2019Q3 2020Q2 2021Q1 2021Q4 2022Q3 2023Q2 2024Q1  \n\n---\nSource 3 Metadata: {'id': 'MTJhMGE2NTctZjMwZC00Zjc4LWJjNjUtZGMzZjFmYTQ2ZTY1', 'Header 1': 'A RESILIENT ECONOMY', 'Header 2': 'A. What Has Underpinned the Post-Pandemic Strength in Demand?'}\nSource 3 Content: # A. What Has Underpinned the Post-Pandemic Strength in Demand?  \n2\\. The unprecedented increase in the fiscal deficit during the depths of the pandemic\nprovided significant fuel to demand. The cumulative increase in federal spending in 2020-21 was\naround 19 percent of GDP. While somewhat smaller than that of the Euro Area, the extraordinary\nbreadth of this (relatively untargeted) fiscal support is providing a material boost to aggregate\ndemand in 2023-24 through multiple channels:  \nÂ· Federal transfers to households (through stimulus checks, food assistance, child and earned\nincome tax credits, and unemployment insurance), combined with foregone consumption and\ndebt rescheduling (e.g., of mortgages and student loans), added an estimated 10 percent of\nGDP to household savings by end-2021. These resources were then subsequently available to\nsupport consumption even as real disposable income fell (due to the post-pandemic burst of\ninflation).  \nÂ· Large transfers to state and local governments prevented a drawdown of rainy-day funds in the\npandemic, providing subnational governments with sizable buffers which, in turn, allowed them\nto maintain their spending above pre-pandemic levels.  \nÂ· Around 31/2 percent of GDP in federal loans provided through the Payroll Protection Program\nwere subsequently forgiven, bolstering corporate balance sheets. Other targeted pandemic\nmeasures (e.g., for airlines) also supported the corporate sector.  \n\n---\n\nNow, here is the question:\n---\nQuestion:\nWhat was the country with the lowest real GDP in 2023?\n---\nThinking Process::: \nAnswer::: \n\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1744300645605
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1744300650648
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Chat model: {AZURE_OPENAI_CHAT_DEPLOYMENT_NAME}\")\n",
        "print(f\"Chat API version: {AZURE_OPENAI_CHAT_API_VERSION}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Chat model: gpt-4o\nChat API version: 2025-01-01-preview\n"
        }
      ],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1744300652499
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm = AzureChatOpenAI(model=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
        "                            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "                            azure_ad_token_provider=token_provider,\n",
        "                            api_version=AZURE_OPENAI_CHAT_API_VERSION,\n",
        "                            temperature=0.7)"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1744300655600
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the LLM's answer to the query with the retrieved documents as additional context\n",
        "answer = chat_llm.invoke(prompt)"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1744300658432
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "To determine the country with the lowest real GDP in 2023, we need to look at the percent deviation from the pre-crisis trend for various regions and countries. The information provided in Source 0 includes a bar chart titled '2023 Real GDP' which shows these percent deviations.\n\nFrom Source 0, we have the following percent deviations for various regions:\n- United States: 0.5%\n- Japan: -1.0%\n- Canada: -1.0%\n- Euro Area: -1.0%\n- United Kingdom: -4.0%\n- G-20 Emerging Markets (EMs): -3.0%\n\nAmong these regions and countries, the United Kingdom has the largest negative deviation, close to -4.0%. This indicates that the United Kingdom had the lowest real GDP relative to its pre-crisis trend in 2023.\n\nAnswer: The United Kingdom had the lowest real GDP in 2023 relative to its pre-crisis trend.\n"
        }
      ],
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1744300660502
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "my_env",
      "language": "python",
      "display_name": "my_env"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "my_env"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}