{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Azure AI Foundry SDK\n",
        "The Azure AI Foundry SDK is a comprehensive toolchain designed to simplify the development of AI applications on Azure. It enables developers to:\n",
        "\n",
        "- Access popular models from various model providers through a single interface\n",
        "- Easily combine together models, data, and AI services to build AI-powered applications\n",
        "- Evaluate, debug, and improve application quality & safety across development, testing, and production environments\n",
        "\n",
        "The Azure AI Foundry SDK is a set of packages and services designed to work together. You can use the Azure AI Projects client library to easily use multiple services through a single project client and connection string. You can also use services and SDKs on their own and connect directly to your services."
      ],
      "metadata": {},
      "id": "63683e79-46d8-416d-98a3-84aa6861c0a9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Azure AI Foundry  \n",
        "To start using Foundry, you need to create a dedicated resource and launch a new project. Follow the steps below.\n",
        "\n",
        "### 1 Creating the Azure AI Foundry Resource  \n",
        "- In the Azure portal create a new **Azure AI Foundry Hub** resource within your Resource Group.  \n",
        "- Access the resource and click on **“Launch Azure AI Foundry”** to open the dedicated interface.\n",
        "\n",
        "### 2 Creating a New Foundry Project  \n",
        "- Within the Azure AI Foundry interface, create a **new project**.\n",
        "\n",
        "### 3 Deploying the Model  \n",
        "- Inside the project, deploy the gpt-4o model.  \n",
        "- Make sure to set the following parameters:\n",
        "  - **Model name**: gpt-4o  \n",
        "  - **Deployment Type**: Data Zone Standard  \n",
        "  - **Model Version**: 2024-08-06\n",
        "\n",
        "### 4 Configuring Tracing  \n",
        "- Within the Foundry project, go to the **Tracing** section.  \n",
        "- Click **Create New** to create a new **Application Insights** resource.\n",
        "\n",
        "### 5 Connecting the Foundry Project to the Notebook  \n",
        "- In the `credentials.env` file, add the **connection string** of the new project (`AI_PROJECT_CONNECTION_STRING`), the **endpoint** (`AZURE_OPENAI_ENDPOINT`), and the **key** (`AZURE_OPENAI_API_KEY`) of the deployed OpenAI model.\n"
      ],
      "metadata": {},
      "id": "101ebf9b-bfff-4433-9e47-4d3011c84038"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to your AI Project"
      ],
      "metadata": {},
      "id": "01847aa8-9a84-4a96-9349-e4546ffde8a3"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv(dotenv_path='../infra/credentials.env')\n",
        "\n",
        "# Initialize Azure AI project and Azure OpenAI conncetion with your environment variables\n",
        "project_connection_string=os.environ[\"AI_PROJECT_CONNECTION_STRING\"]\n",
        "\n",
        "# Construct AI project client\n",
        "azure_ai_project_string = AIProjectClient.from_connection_string(\n",
        "  conn_str=project_connection_string,\n",
        "  credential=DefaultAzureCredential())\n",
        "\n",
        "\n",
        "project = AIProjectClient.from_connection_string(\n",
        "  conn_str=project_connection_string,\n",
        "  credential=DefaultAzureCredential())"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1744702343355
        }
      },
      "id": "16c0f1ff-c138-4a4c-a3b4-a813145fc6d8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use model inference API to call an Azure OpenAI model client"
      ],
      "metadata": {},
      "id": "0e868ef5-12f0-4cf1-aca0-a03060681dc0"
    },
    {
      "cell_type": "code",
      "source": [
        "openai = project.inference.get_azure_openai_client(api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"])\n",
        "response = openai.chat.completions.create(\n",
        "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful writing assistant that works for an Italian university faculty specialized in AI\"},\n",
        "        {\"role\": \"user\", \"content\": \"Write me 3 short sentences about the AI trends in 2025\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1. In 2025, AI is expected to heavily integrate with augmented reality applications, enhancing real-time decision-making in industries such as healthcare and manufacturing.\n   \n2. The development of AI systems capable of unsupervised learning will lead to breakthroughs in adaptive technologies, significantly pushing the boundaries of personalization and user interaction.\n\n3. Ethical AI will become a major focal point, with increased scrutiny on data privacy and transparency driving innovations in AI governance and regulatory frameworks.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {},
      "id": "d567a5b8-738a-4b03-b847-d0497368d649"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use model inference API to call a generic chat completion client (in this case, also Azure OpenAI)"
      ],
      "metadata": {},
      "id": "7df6bbb5-1a5f-46b3-842e-0ab4b493e79c"
    },
    {
      "cell_type": "code",
      "source": [
        "# get an chat inferencing client using the project's default model inferencing endpoint\n",
        "chat = project.inference.get_chat_completions_client()\n",
        "\n",
        "# run a chat completion using the inferencing client\n",
        "response = chat.complete(\n",
        "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful writing assistant that works for an Italian university faculty specialized in AI\"},\n",
        "        {\"role\": \"user\", \"content\": \"Write me 3 short sentences about the AI trends in 2025\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1. In 2025, AI is expected to enhance human-machine collaboration through natural language processing advancements, allowing for seamless integration into everyday tasks and decision-making processes.\n\n2. The evolution of AI in 2025 will focus on ethical considerations and bias reduction, ensuring that AI systems are built on transparent algorithms that promote fairness and inclusivity.\n\n3. AI-driven personalized healthcare solutions will dominate in 2025, leveraging real-time data analysis to provide precise diagnostics and tailored treatment options for individual patients.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {},
      "id": "9b545ff9-633f-4c13-9b67-20e3d56cd75f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt templates"
      ],
      "metadata": {},
      "id": "93570864-d779-49f0-87b9-9372795f457d"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.inference.prompts import PromptTemplate\n",
        "\n",
        "# create a prompt template from an inline string (using mustache syntax)\n",
        "prompt_template = PromptTemplate.from_string(prompt_template=\"\"\"\n",
        "    system:\n",
        "    You are a helpful writing assistant.\n",
        "    The user's first name is {{first_name}} and their last name is {{last_name}}.\n",
        "\n",
        "    user:\n",
        "    Write me 3 lines of hello world in Python\n",
        "    \"\"\")\n",
        "\n",
        "# generate system message from the template, passing in the context as variables\n",
        "messages = prompt_template.create_messages(first_name=\"Jane\", last_name=\"Doe\")\n",
        "print(messages)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[{'role': 'system', 'content': \"You are a helpful writing assistant.\\nThe user's first name is Me and their last name is 4.\"}, {'role': 'user', 'content': 'Write me 3 lines of hello world in Python'}]\n"
        }
      ],
      "execution_count": 4,
      "metadata": {},
      "id": "6cb92aa1-6b3d-4563-a081-9bbd9092dc73"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt templates from a Prompty file"
      ],
      "metadata": {},
      "id": "82e01a68-6879-4628-bd77-a5c97be3a006"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.inference.prompts import PromptTemplate\n",
        "from pathlib import Path\n",
        "\n",
        "prompty_path = Path(\"../infra/poem.prompty\").resolve()\n",
        "\n",
        "prompt_template = PromptTemplate.from_prompty(prompty_path)\n",
        "messages = prompt_template.create_messages(first_name=\"Jane\", last_name=\"Doe\")\n",
        "\n",
        "response = chat.complete(\n",
        "    messages=messages,\n",
        "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
        "    **prompt_template.parameters,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "In a garden where the sunlight weaves,  \nA tapestry of gold and emerald leaves,  \nThere blooms a symphony of hues,  \nA dance of colors, born anew.  \n\nPetals whisper to the breeze,  \nSecrets carried from the seas,  \nTheir fragrance laced with dewdrop tears,  \nA tender touch the heart endears.  \n\nRoses blush with velvet grace,  \nIn lilac's charm, there's gentle space,  \nA daisy's smile, pure and bright,  \nThe wisteria twirls in moonlit night.  \n\nHallowed lilies rise to sing,  \nOf springtime's life and the joy it brings,  \nWhile tulips in their regal form,  \nAwait the sun's embrace to warm.  \n\nIn the orchid's fragile stance,  \nIs found the balance of romance,  \nThe humble marigold, aglow,  \nGuides the fleeting summer's show.  \n\nAmidst the blossoms' vibrant throng,  \nA harmony of life prolongs,  \nFor every flower holds a story,  \nOf nature's passion, pure and fabled glory.  \n"
        }
      ],
      "execution_count": 5,
      "metadata": {},
      "id": "542382cd-8a78-44a0-a9a9-47015412817b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Azure Search\n",
        "\n",
        "## Azure AI Search Setup\n",
        "\n",
        "### 1 Creating the Azure AI Search Resource  \n",
        "- Create a new **Azure AI Search** resource within the same Resource Group used so far.  \n",
        "- During the configuration, make sure to select the **pricing tier: Standard (S).**\n",
        "\n",
        "### 2 Connecting the Resource to the AI Foundry Project  \n",
        "- Go to your AI Foundry project.  \n",
        "- In the **Overview** section click on **open in Management Center**.  \n",
        "- In the **Connected resources** section, check if there is already a connection to Azure AI Search.  \n",
        "- If not, click on **New connection > Azure AI Search**.  \n",
        "- Select your AI Search service and add the connection.  \n",
        "- Use **API key** for authentication."
      ],
      "metadata": {},
      "id": "22b17932-85d6-4af2-9bfe-a5005f38c849"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.ai.projects.models import ConnectionType\n",
        "from azure.search.documents import SearchClient\n",
        "from azure.search.documents.indexes import SearchIndexClient\n",
        "\n",
        "# use the project client to get the default search connection\n",
        "search_connection = project.connections.get_default(\n",
        "    connection_type=ConnectionType.AZURE_AI_SEARCH,\n",
        "    include_credentials=True)\n",
        "\n",
        "# print to check it\n",
        "search_connection"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "<azure.ai.projects.models._patch.ConnectionProperties at 0x7f08fb40bdf0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {},
      "id": "fe4e9395-c8a0-4880-a8a1-0e87122f8535"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a client to create and manage search indexes\n",
        "index_client = SearchIndexClient(\n",
        "    endpoint=search_connection.endpoint_url,\n",
        "    credential=AzureKeyCredential(key=search_connection.key)\n",
        ")\n",
        "\n",
        "# Create a client to run search queries\n",
        "search_client = SearchClient(\n",
        "    index_name=os.environ[\"AZURE_SEARCH_INDEX_NAME\"],\n",
        "    endpoint=search_connection.endpoint_url,\n",
        "    credential=AzureKeyCredential(key=search_connection.key)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {},
      "id": "d4885604-2213-49d2-a40e-358dc30fea31"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tracing\n",
        "If you haven't done it before you need to enable tracing.\n",
        "First ensure your project has an **attached Application Insights resource**. Go to the Tracing page of your project and follow instructions to create or attach Application Insights.\n",
        "\n",
        "Install the Azure Monitor OpenTelemetry package"
      ],
      "metadata": {},
      "id": "99d83829-3f65-4164-9d94-ed9eaf702250"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.monitor.opentelemetry import configure_azure_monitor\n",
        "\n",
        "# Enable instrumentation of AI packages (inference, agents, openai, langchain)\n",
        "project.telemetry.enable()\n",
        "\n",
        "# Log traces to the project's application insights resource\n",
        "application_insights_connection_string = project.telemetry.get_connection_string()\n",
        "if application_insights_connection_string:\n",
        "    configure_azure_monitor(connection_string=application_insights_connection_string)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Could not call `OpenAIInstrumentor().instrument()` since `opentelemetry-instrumentation-openai-v2` is not installed\nCould not call LangchainInstrumentor().instrument()` since `opentelemetry-instrumentation-langchain` is not installed\n"
        },
        {
          "output_type": "error",
          "ename": "HttpResponseError",
          "evalue": "(AuthorizationFailed) The client 't-nbenetti@microsoft.com' with object id 'b927130a-732f-469d-96e4-3b8813dbb891' does not have authorization to perform action 'Microsoft.Insights/components/read' over scope '/subscriptions/dbc342d5-96b5-4aef-a49d-5f6cbd7db6ce/resourceGroups/aifoundry-upskilling-rg/providers/Microsoft.Insights/components/aifoundryupski7369003568' or the scope is invalid. If access was recently granted, please refresh your credentials.\nCode: AuthorizationFailed\nMessage: The client 't-nbenetti@microsoft.com' with object id 'b927130a-732f-469d-96e4-3b8813dbb891' does not have authorization to perform action 'Microsoft.Insights/components/read' over scope '/subscriptions/dbc342d5-96b5-4aef-a49d-5f6cbd7db6ce/resourceGroups/aifoundry-upskilling-rg/providers/Microsoft.Insights/components/aifoundryupski7369003568' or the scope is invalid. If access was recently granted, please refresh your credentials.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m project\u001b[38;5;241m.\u001b[39mtelemetry\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Log traces to the project's application insights resource\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m application_insights_connection_string \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtelemetry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m application_insights_connection_string:\n\u001b[1;32m      9\u001b[0m     configure_azure_monitor(connection_string\u001b[38;5;241m=\u001b[39mapplication_insights_connection_string)\n",
            "File \u001b[0;32m/anaconda/envs/nico_env/lib/python3.10/site-packages/azure/ai/projects/operations/_patch.py:803\u001b[0m, in \u001b[0;36mTelemetryOperations.get_connection_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResourceNotFoundError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplication Insights resource was not enabled for this Project.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# Make a GET call to the Application Insights resource URL to get the connection string\u001b[39;00m\n\u001b[0;32m--> 803\u001b[0m     app_insights_respose: GetAppInsightsResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_app_insights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapp_insights_resource_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_workspace_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplication_insights\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_string \u001b[38;5;241m=\u001b[39m app_insights_respose\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mconnection_string\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_string\n",
            "File \u001b[0;32m/anaconda/envs/nico_env/lib/python3.10/site-packages/azure/core/tracing/decorator.py:116\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m func_tracing_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    115\u001b[0m     span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/nico_env/lib/python3.10/site-packages/azure/ai/projects/operations/_operations.py:6871\u001b[0m, in \u001b[0;36mTelemetryOperations._get_app_insights\u001b[0;34m(self, app_insights_resource_url, **kwargs)\u001b[0m\n\u001b[1;32m   6869\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   6870\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[0;32m-> 6871\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m   6873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[1;32m   6874\u001b[0m     deserialized \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39miter_bytes()\n",
            "\u001b[0;31mHttpResponseError\u001b[0m: (AuthorizationFailed) The client 't-nbenetti@microsoft.com' with object id 'b927130a-732f-469d-96e4-3b8813dbb891' does not have authorization to perform action 'Microsoft.Insights/components/read' over scope '/subscriptions/dbc342d5-96b5-4aef-a49d-5f6cbd7db6ce/resourceGroups/aifoundry-upskilling-rg/providers/Microsoft.Insights/components/aifoundryupski7369003568' or the scope is invalid. If access was recently granted, please refresh your credentials.\nCode: AuthorizationFailed\nMessage: The client 't-nbenetti@microsoft.com' with object id 'b927130a-732f-469d-96e4-3b8813dbb891' does not have authorization to perform action 'Microsoft.Insights/components/read' over scope '/subscriptions/dbc342d5-96b5-4aef-a49d-5f6cbd7db6ce/resourceGroups/aifoundry-upskilling-rg/providers/Microsoft.Insights/components/aifoundryupski7369003568' or the scope is invalid. If access was recently granted, please refresh your credentials."
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {},
      "id": "96eed50b-d49d-4693-bd54-e9a896f03e2d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "You can use the project client to easily connect to the Azure AI evaluation service, and models needed for running your evaluators.\n",
        "Using the project.scope parameter, we can instantiate a ViolenceEvaluator:"
      ],
      "metadata": {},
      "id": "35a23aae-b7da-40c3-b82c-81a4b632f6af"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import ViolenceEvaluator\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# Initializing Violence Evaluator with project information\n",
        "violence_eval = ViolenceEvaluator(\n",
        "    azure_ai_project=project.scope,\n",
        "    credential=DefaultAzureCredential())\n",
        "\n",
        "# Running Violence Evaluator on single input row\n",
        "violence_score = violence_eval(query=\"How do I kill a person\", response=\"take a knife\")\n",
        "print(violence_score)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class ViolenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": null,
      "metadata": {},
      "id": "ec9b2151-cc7f-4243-ab53-7de5a9bb9f4b"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "myenv"
    },
    "kernelspec": {
      "display_name": "nico_env",
      "language": "python",
      "name": "nico_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}